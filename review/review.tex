\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{titling}
\usepackage[backend=biber, style=numeric]{biblatex}
\usepackage[margin=0.5in]{geometry}
\usepackage{multicol}

\bibliography{review}

\title{A systematic literature review of machine learning models for train delay prediction}
\author{D. White, N. Al-Moubayed}
\date{\today}

\begin{document}
\begin{titlingpage}

\maketitle
\begin{abstract}

\textit{Context}: train delay prediction (TDP) 

To identify a suitable paper to use as a basis for the author's own work.

Train delays impose a huge cost on both train operators and passengers. A preliminary analysis of historical delay attribution data released by Network Rail (NR) shows that
35 million minutes of delay were experienced by passengers in the 2018 - 2019 financial year. The prediction of train delays allows the rescheduling or re-routing of crews and rolling-stock,
the reduction in the the amount of delay, and improvement of information available to passengers, and subsequent better decision-making. 

\textit{Objective}: the goal of this work is to synthesise available research results to inform evidence-based selection of a machine learning (ML) model for TPD suitable for replication by the author.

\textit{Method}: relevant studies about ML techniques were gathered via a systematic literature review. Supporting contextual studies were also gathered.

\textit{Results}: 19 studies were selected. 13 distinct models are used: Bayesian networks, support vector regression, random forests, neural networks, fuzzy Petri nets, extreme learning machines, various forms of regression () 
The data used, and results obtained, are compared. 

To identify a replicable study using UK daata.

\textit{Conclusion}: to do.

\end{abstract}
\end{titlingpage}

\tableofcontents
\clearpage

\section{Introduction}

\subsection{Delays}

A \textit{delay} is a "positive deviation between the realized time and scheduled times of [an] activity" \cite{cerreto_nielsen_harrod_nielsen_2016}. In this case, the activity is either the departure or arrival of a train.  Although precise terminology differs, the literature agrees that there are two principal classes of delay \cite{olsson_haugland_2004}: primary and secondary.

\subsubsection{Primary delays}

A \textit{primary} or \textit{exogenous} delay is "caused by external stochastic disturbances" \cite{oneto_et_al_2016}. The causes of primary delays are varied and numerous \cite{berger_et_al_2011}\cite{cerreto_nielsen_harrod_nielsen_2016}\cite{milinkovic_et_al_2013}\cite{nr_delay_causes} and many different classifications exist. For the purposes of this dissertation, the following classification is proposed:

\begin{itemize}
	\item \textit{Weather}: severe heat, flooding, landslips, leaves, snow, and ice
	\item \textit{Passenger}: prolonged alighting and boarding times
	\item \textit{Maintenance}: construction work, repair work
	\item \textit{Other}: accidents, vandalism, trespassing, fatalities, strikes, holidays
\end{itemize}

A large component of this dissertation is the effect of the inclusion of exogenous data on the predictive capability of various machine learning techniques: this classification broadly follows the datasets that will
be considered.

\subsubsection{Secondary delays}

A \textit{secondary} (\textit{knock-on}, \textit{consecutive}) delay is "generated by operations conflicts" \cite{cerreto_nielsen_harrod_nielsen_2016}, i.e. primary delays. Secondary delays often affect
both the route on which the primary delay occurred and any connecting routes; delays 'cascade' as "trains, drivers, and crews aren't in the right place at the right time to run other services" \cite{nr_knock_on_delays},
or as trains are held according to waiting policies \cite{berger_et_al_2011}. Secondary delays cannot be exactly forecast \cite{berger_et_al_2011}\cite{milinkovic_et_al_2013} because they are influenced by multiple interacting factors: the severity of the primary delay, the timetable of the train, infrastructure, and even the behaviour of the driver.

\subsection{Timescales}

TPD models are either \textit{online}, in which they are dynamically updated with new data as it becomes available, or \textit{offline}. Models can be further subdivided into whether they are used to predict train delays in real-time, or in the future, though this is not a perfect delineation: \cite{nair_et_al_2019} merges these categories in an ensemble by utilising different underlying models.   Real-time models are by necessity online, and make up the majority of TDP systems.

Future models can be further broken down into short-term and long-term. Long-term "tactical" \cite{markovic_et_al_2015} models are used for timetabling and resource planning. Short-term models are relatively rare, and are typically constrained by features which can only be forecast up to a limit. In TDP, this is weather, as in \cite{nair_et_al_2019}\cite{wang_et_al_2019}.

\subsection{Metrics}

Two key metrics are used to measure delays, and more broadly, performance: punctuality and reliability. 

\subsubsection{Punctuality}

\textit{Punctuality} is "a feature consisting in that a predefined vehicle arrives, departs, or passes at a predefined point at a predefined time" \cite{rudnicki_1997}. This definition has the interesting effect that trains 
that arrive \textit{early} cannot be considered punctual. However, the use of punctuality hides a lot of information \cite{skagestad_2004}; reliability and variability are better metrics \cite{olsson_haugland_2004}. As variability is infrequently used, it is disregarded here. The Office of Road and Rail (ORR), the UK's railway regulator, uses Public Performance Measure (PPM) to assess punctuality.

\subsubsection{Reliability}

\textit{Reliability} has several measures \cite{rietveld_bruinsma_van_vuuren_2001}: typically, it is taken it taken to be the probability that a train arrives $x$ minutes late (i.e. is punctual). ORR uses Cancellations and Significant Lateness (CaSL) to assess reliability.

% OVERVIEW OF SYSTEMATIC LITERATURE REVIEW METHOD
\clearpage
\section{Overview of systematic literature review method}

A systematic literature review (SLR) is "a means of evaluating and interpreting all available research relevant to a particular research question or topic area or phenomenon of interest" \cite{williams_hollingsworth_2005}. The research questions that this SLR are intended to answer are:

\begin{itemize}
	\item RQ1: What ML models are commonly used for TDP?
	\item RQ2: What exogenous data is used to improve the performance of those models?
	\item RQ3: What are the current research areas of TDP?
\end{itemize}

The SLR was based on a recent literature review \cite{ghofrani_et_al_2018}, the methodology of which is discussed thoroughly below. The studies identified in \cite{ghofrani_et_al_2018} are used to select key search terms for further database queries. Additionally, the cited references of those studies were used to find other relevant papers. These studies are then selected for inclusion in this review by title, abstract, and finally by content on their relevance to the application of ML to TDP.

\subsection{Recent applications of big data analytics in railway transportation systems: A survey \cite{ghofrani_et_al_2018}}

Only an overview of content relevant to this literature review is presented here.
The authors identified the following data-related keywords and railway transportation system (RTS) -related keywords. Of particular significance here is "Railway Operations", which covers the actual \textit{running} of trains on a RTS, and therefore delays. 

The authors limited the scope of their search to papers in scientific journals, conferences, and dissertations in English from the last 15 years (i.e. 2003 - 2017). They specifically included only papers with quantitative results. They searched ScienceDirect, Emeralds, Scopus, EBSCO, and IEEE Xplore, and also used cited references of studied papers as a source. 115 papers were found and were classified by a four-layer structure:

\begin{enumerate}
	\item Area of RTS: Maintenance, Operations, Safety
	\item Analytic category: descriptive, predictive, prescriptive
	\item BDA model: clustering, numeric prediction, association, statistical analysis, image processing, and so on.
	\item Implementation technique: Bayesian network, SVM, SVR, Decision Tree, ANN, Regression
\end{enumerate}

We are interested in Operations; papers in the other areas are disregarded. Within Operations, the authors discuss the applications of BDA to RTS, data collection and sources in RTS, and finally the studies themselves.
Only those that focus on TPD are considered. In total, 19 papers were selected by title for inclusion in this literature review; they provided the foundation for a subsequent database search.

\subsection{Database search}

The papers selected from \cite{ghofrani_et_al_2018} were used to identify the following key search terms: "train", "delay" and "prediction". Alas, "train" is a common word in scientific literature, and this confounded initial results somewhat. Appropriate synonyms were identified for each term. The following databases, based on those used by \cite{heckman_williams_2011}, were searched:

\begin{multicols}{2}

\begin{itemize}
	\item ACM Digital Library
	\item IEEE Xplore
	\item ScienceDirect
	\item SpringerLink
\end{itemize}

\end{multicols}

Where possible, the discipline was restricted to Computer Science. Approximately 3000 studies were identified; some post-processing was necessary to reduce the number of studies retrieved. In total, 69 studies were selected.

%ScienceDirect yielded 73 articles, of which 44 were selected by title. 
%SpringerLink yielded 119 articles, of which 11 were selected by title.
%ACM yielded 9 articles, of which 5 were selected by title.
%IEEE Explore yield 22 articles, of which 9 were selected by title.

\subsection{Study selection}

Study selection was a three-stage process:

\begin{enumerate}
	\item Initial selection by title
	\item Selection by abstract
	\item Further selection by content
\end{enumerate}

Of the 88 total studies found, 5 were duplicates. 64 studies were excluded by extract, and 8 by content. 4 studies were discovered through other means - either from a preliminary, less structured, search, or from cited references. In total, 15 relevant papers were identified.

% STUDIES
\section{Overview of studies}

We identified 15 studies in the literature that focus on the application of ML to TPD. An preliminary analysis shows that all work occurred in the past decade (i.e. during, or after, 2010), with most studies (47\%) published in 2017 and 2019.

\begin{table}[h]
\centering
\begin{tabular}{ll}
\noalign{\smallskip}\hline \noalign{\smallskip}
Year  & \# \\	\noalign{\smallskip}\hline \noalign{\smallskip}
2010  & 1  \\
2011  & 1  \\
2012  & 1  \\
2014 & 1	\\
2015  & 2  \\
2016  & 2  \\
2017  & 4  \\
2018  & 3  \\
2019 & 5  \\ 	\noalign{\smallskip}
Total & 19 \\  \noalign{\smallskip}\hline
\end{tabular}
\end{table}

13 distinct ML techniques were identified. 29 were applied in total, as several papers compared and contrasted different techniques, or variations of the same technique (as in \cite{lessan_fu_wen_2019}\cite{oneto_et_al_2016}\cite{milinkovic_et_al_2013}\cite{markovic_et_al_2015}), or even combined multiple models (emsemble model of \cite{nair_et_al_2019}; in these cases, each distinct 'usage' is counted separately. 

The most popular techniques are random forests (20\%) and extreme learning machines (17\%)., although these figures are skewed by the inclusion of four papers CITE HERE which are closely related.

Some studies use techniques that may be more accurately classified as 'statistics' rather than ML (i.e. simple variants of regression, as in \cite{pongnumkul_pechprasarn_kunaseth_chaipah_2014}\cite{wang_work_2015}) or which are closer to \textit{algorithmic} models than ML (\cite{hansen_goverde_van_der_meer_2010}); however, as these lines is blurred, and for completeness' sake, all were selected for inclusion in this review.

Many defy easy classification. RFR should be just RF. Dynamic interpretable should be under Ensemble.
The focus of this review was very specific

\begin{table}[h]
\begin{tabular}{lll}
\noalign{\smallskip}\hline \noalign{\smallskip}
ML model & Acronym & \# \\ 	\noalign{\smallskip}\hline \noalign{\smallskip}
Bayesian network & BN & 4 \\
Kernel method & KN & 1 \\
Extreme learning machine & ELM & 5 \\
Random forest & RF & 6 \\
Fuzzy Petri net & FPN & 1 \\
Adaptive neural fuzzy inference system & ANFIS & 1 \\
Gradient-boosted regression trees & GBRT & 1 \\
$k$-nearest neighbour & $k$-NN & 1 \\
Artificial neural network & ANN & 2 \\
Support vector regression & SVR & 2 \\
Kernel regression & KR & 2 \\
Markov &  & 2 \\
Decision tree & DT & 1 \\ 	\noalign{\smallskip}
Total                                    &         & 29	\\ \noalign{\smallskip} \hline
\end{tabular}
\end{table}

\section{ML models}

In this section, each of the distinct ML models identified previously is discussed. For studies that compare multiple models, the model the authors found to be superior is used. 

% Millie uses:
% objectives
% method limitations
% evaluation methodology
% evaluation subjects (dataset)
% evaluation results (easy)

% BAYESIAN NETWORKS
\subsection{Bayesian networks}

A Bayesian network (BN) is a "probabilistic graphical model that uses Bayesian inference for probability computations" \cite{towards_data_science_BN_intro}. Each directed edge models a conditional independence, allowing "the incorporation of massive historical data" \cite{lessan_fu_wen_2019}. BNs allow the updating of probability distributions and reduce the uncertainty of future train delays in real-time as more data continuously comes available from the monitoring system \cite{corman_kecman_2018}.

%The structure of a BN is fixed by the operating plan (e.g. a timetable). Historical traffic data is used to calibrate the resulting BN with conditional probability distributions. and regression coefficients for every two dependent events. 

% LESSAN ET AL, 2019
\subsubsection{A hybrid Bayesian network model for predicting delays in train operations \cite{lessan_fu_wen_2019}}

\textit{Objectives}: To identify which BN architectures are most valid / reliable for predicting train delays for a particular network structure.

\smallskip

\textit{Timescale}: offline; short-term; long-term

\smallskip

\textit{Methodology}: Compared three different BN schemes: heuristic hill-climbing, primitive linear, and hybrid. The data is used to rationalise the dependency graph of the BNs. Each is then trained with $k$-fold cross validation to avoid over-fitting and to evaluate performance. The hybrid BN is based on the structure from the former two schemes, and subsequently refined using domain knowledge and expert judgements about the sequences of stations and the relationships between consecutive train operations. This structure is intended to differentiate between the delay propagated from upstream operations and that due to the most recently performed operation in the prediction process. Continuous variables were discretised; specifically, 3 minutes was used as a width for prediction intervals (as late arrivals of less than 90s are not considered delays).

\smallskip

\textit{Data}: Data comes from train operations on the Wuhan-Guangzhou (WH-GZ) high-speed rail (HSR) line in China. The line is 1096km long, with 18 stations. Only 15 stations and 14 sections were used due to jurisdiction. Date was collected between February 2015 to November 2015, comprising approximately 380,000 arrival and departure events between stations on the specified line, excluding early arrivals and departures.

\smallskip

\textit{Results}: The first hybrid BN-based prediction model in the literature. The reconstructed hybrid heuristic BN was found to be perform the best out of the three, with an 80\% prediction accuracy within a 60-minute horizon, a MAE of 30s, a RMSE of less than two minutes (suggesting the presence of outlier prediction errors). No-information rate of 58\%. Sensitivity was $>60\%$. Model is simple, interpretable, and computationally efficient. They also note that prediction errors soon accumulate, and that this could be addressed using an online model, as in \cite{corman_kecman_2018}.

% CORMAN AND KECMAN, 2018
\subsubsection{Stochastic prediction of train delays in real-time using Bayesian networks \cite{corman_kecman_2018}}

\textit{Objectives}: To examine the effect that the prediction horizon and incoming information about a running train may have on the predictability of subsequent arrival and departure times of all trains. To answer the question: how does the prediction of a single delay event change over time as the same event approaches the time \textit{now}?

\smallskip

\textit{Timescale}: online; real-time

\smallskip

\textit{Methodology}: Developed a stochastic model for predicting the propagation of train delays based on BNs. Extended by modelling the interdependence between trains that share the same infrastructure or a scheduled passenger transfer (i.e. a connection).

\smallskip

\textit{Data}: The model was tested on a 180km double-track mixed traffic line between Stockholm and Norrkoping, in Sweden. 90\% of traffic is passenger trains. The line comprises 27 stations and junctions; 10 of these accommodate scheduled stops of passenger and freight trains. Approximately 300 trains per day traverse the corridor. Two months' worth of data, 1 January - 28 February 2015, was gathered from the Swedish infrastructure manager Trafikverket. The punctuality performance of the dataset is within 0.4\% of the average performance for the whole of 2015. No strong seasonaility effect is present in the performance of the Swedish network. All event times are rounded to full minutes. Their database comprises the scheduled and realised times for departures, arrivals, and through runs for all trains and stations. 

\smallskip

\textit{Results}: accuracy of predictions is significantly increased within the 30-minute prediction horizon. Median error increases very slowly. S.D of the probability of an occurrence of an event, as predicted half an hour ahead of time, is 2 minutes. Major contribution is the representation of delays due to interactions between trains. 

% NEURAL NETWORKS
\subsection{Neural networks}

Neural networks are models based on human brains. The oldest application of ML to the general problem of predicting delays in public transport that the authors are aware of used a NN \cite{peters_et_al_2005}.  This study was not selected for inclusion in this review, however. The popularity of neural network has declined in recent years as more sophisticated models have been developed; they are primarily used as a benchmark in the studies selected for this review. 

%YAGHINI ET AL 2013
\subsubsection{Railway passenger train delay prediction via neural network model \cite{yaghini_et_al_2013}}

\textit{Objectives}: To develop a high-precision neural network model to predict the late arrival of passenger trains in Iran.

\smallskip

\textit{Timescale}: Offline; real-time; short-term; long-term

\smallskip

\textit{Data}: Data from 2005 to the end of 2009 is used. This comprises approximately 180,000 passenger trains, with a total delay of approximately 5.5 million minutes. Stopping time at interval stations (i.e. dwell time) for praying, boarding, and alighting are excluded from delay time.  

\smallskip

\textit{Methodology}: Compares three different input methods (normalised real number, binary coding, and binary set encoding) for a neural network model. Used decision trees and multiple logistic regression to evaluate the quality of results. Also compared three different architectures: quick, dynamic, and multiple. Quick trains a single network; dynamic adds nodes until a specified level of performance is reached; multiple trains networks in parallel and selects the most accurate. 

\smallskip

\textit{Results}: The accuracy level of the binary quick model was found to be superior to other statistical models such as decision tree and multinomial logistic regression models, though with significantly longer training time.

% RANDOM FORESTS
\subsection{Random forests}
 
Random forests were first introduced by \cite{ho_1995}. A random forest is a collection of individual decision trees. Simply put, each individual tree predicts the class of an input and the class with the most votes is the output of the model. This improves accuracy and reduces overfitting. Decision trees in which the target variable can take a discrete set of values are called classification trees; those that take continuous variables, regression trees. Leaves represent class labels and branches conjunctions of feature that lead to that class. Accuracy depends on the number of trees composing the forest,  the accuracy of each tree, and the correlation between them \cite{breiman_2001}. Accuracy converges to a limit as the number of trees increases, and rises as the accuracy of each tree increases and the correlation between them decreases.

%ONETO ET AL 2016
\subsubsection{Advanced Analytics for Train Delay Prediction Systems by Including Exogenous Weather Data \cite{oneto_et_al_2016}}

\textit{Objectives}: To build a data-driven train prediction system that exploits the most recent analytics tools.

\smallskip

\textit{Timescale}: online; real-time

\smallskip

\textit{Methodology}: The authors compared kernel methods, extreme learning machines, and random forests. The random forest comprised 500 trees. For each train and algorithm, a model is build. The hyperparameters of each model are tuned. The models are then applied to the current state of the trains, and finally they are validated (i.e. predictions are compared to actual future events). Notably, the authors derive a set of novel Key Performance Indicators (KPIs) to evaluate performance. Approximately 600,000 models would have to be trained daily across the whole network.

\smallskip

\textit{Data}: This studie worked closely with RFI, the Italian railway authority. Used more than 6 months of data relating to two main areas in Italy, including more than 1000 trains and several checkpoints. The study also used weather data, discussed later. 

\smallskip

\textit{Results}: The RF method performed up to twice as well as the current RFI system. Included weather data increased accuracy by approximately 10\%. Both ELM and KM also improve over RFI, though not to the same extent. 

% NABIAN ET AL 2019
\subsubsection{Predicting near-Term Train Schedule Performance and Delay Using Bi-Level Random Forests \cite{nabian_et_al_2019}}

\textit{Objectives}: To predict passenger train delays in the Netherlands.

\smallskip

\textit{Timescale}: online, real-time

\smallskip

\textit{Methodology}: Develops a novel bi-level RF to solve a coupled classification-regression task: identifying \textit{whether} delays will increase, decrease, or remain constant in a fixed timeframe (20 minutes), and then predicting by how much. Assumes that delays have already occurred. Compared to linear regression, multinomial logistic regression, decision trees, $k$-NN, and SVM / SVRs. Assumes that all trains rode on a single track. Each leaf in the primary classification level is a random forest for regression for that classification.

\smallskip

\textit{Data}: Data was provided from the Netherlands' railway infrastructure manager, ProRail, between September 4 2017 and December 9 2017. Includes the planned timetable, actual historical train performance, crew schedules, rolling stock circulation, (limited) infrastructure data: the distance between consecutive stations. 10 million data points over a 13 week period. Excluded Wednesdays (which are apparently particularly busy), and delays longer than 15 minutes.

\smallskip

\textit{Results}: Found that the proposed model provides the best prediction accuracy. Constructing the model is computationally cheap.

%WANG ET AL 2019
\subsubsection{Train delay analysis and prediction based on big data fusion \cite{wang_et_al_2019}}

\textit{Objectives}: To develop a machine-learning model to predict 

\smallskip

\textit{Timeframe}: online; short-term

\smallskip

\textit{Methodology}: unusual in that it focused on short-term delay prediction. Used gradient-boosted regression trees (GBRT). Model predicts delays up to 10 days in advance using weather forecasts. Used density-based clustering algorithm (DBSCAN) to identify a time interval threshold $t_epsilon$, which determines whether the delay of a train at a given station propagates to the following train.  

\smallskip

\textit{Data}: used a three-month dataset of weather, train delay, and train schedule records. The weather data is thoroughly discussed later. Data collected between 1st January to 31st March 2018.
Schedule data for 7172 railway trains was obtained. GIS for 2761 railway stations was obtained from Tencent Maps (including name, longitude, and latitude. Observed nearly 2.7 million delays over the course of three months, of which 37.4\% came from high-speed trains. 

\smallskip

\textit{Results}: In severe weather, train delays are determined mainly by the type of bad weather, but that in ordinary weather train delays are determined mainly by historical delay time and the delay frequency of trains. Proposes concepts of key train delay stations and the time interval threshold. Relatively poor results due to only 3 months' worth of data.

% REGRESSION
\subsection{Regression}

Regression is used to construct a relationship between two or more explanatory variables (independent) and a response (dependent) variable by fitting a linear equation to the data. 

%WANG AND WORK 2015
\subsubsection{Data driven approaches for passenger train delay estimation \cite{wang_work_2015}}

\textit{Objectives}: To develop a historical regression model to estimate future trains delays using only the past performance of a train along a given route.

\smallskip

\textit{Timescale}: offline; online; short-term; real-time.

\smallskip

\textit{Methodology}: developed four regression models, one offline, three online, to predict train delays. Assumes that delays from one trip to the next follow a vector autoregressive process. Assumption is valid because passenger trains operate on a fixed frequency (daily) and schedule, and so prior delays on previous trips hold information to estimate the train delay at each station for the current trip. The vector autoregressive process predicts train delays at each station along the route simultaneously. Determines parameters of regression model through least squares estimation on the training dataset.

\smallskip

\textit{Data}: Data is from 282 Amtrak trains from 2006 – 2013, more than 100,000 train trips. Amtrak trains have operational priority yet the on-time rate of Amtrak is less than 50\%. Average delay for several trains can reach as high as 50 minutes. Coarse; lots of missing records. 

\smallskip

\textit{Results}: Historical regression models improves the RMSE estimate of delay by 12\%. The online proposed model improves the RMSE estimate of delay by 60\%.

% SUPPORT VECTOR REGRESSION
\subsection{Support vector regression}

Support vector regression (SVR) is a popular ML model that uses support vector machines (SVMs) to predict continuous values. 

%BARBOUR ET AL 2018
\subsubsection{Prediction of arrival times of freight traffic on US railroads using support vector regression \cite{barbour_et_al_2018}}

\textit{Objectives}: To develop a data-driven approach to predict estimated arrival times (ETAs) of individual freights trains. 

\smallskip

\textit{Timescale}: Online; real-time 

\smallskip

\textit{Methodology}: Construct distinct regression model for each origin-destination pair for which predictions are required. All of the same form; differ only in feature weights and hyper-parameters. Test four different SVR-based algorithms: three linear, with varying input features, and one RBF (radial basis function) kernel SVR. RBF kernel offers no improvement over fully-featured linear kernel. Only needed to train 140 models. Estimate 10,000 models for all ETA predictions.

\smallskip

\textit{Data}: Used freight train movement, train car operations, crew, and locomotive data. Network data is extracted from dispatching, operations, and signalling data. Final features: train length, train tonnage, train horsepower per ton, train priority, crew time remaining, on duty time to departure, full traffic count, directional traffic count, available sidings. 

\smallskip

\textit{Results}: Large gains from including track segment occupancy features. Results compare closer to a deep NN trained on the same dataset (average improvement of 16\%, max of 25\%)
RBF kernel SVR offers a mean 14.3\% improvement, a max 21.8\%. Don't report on prediction error. Notes the difficulty of using features that change such the amount of traffic on the line of the road, the number of available sidings (as trains enter and leave).

%MARKOVIC ET AL 2015
\subsubsection{Analyzing passenger train arrival delays with support vector regression \cite{markovic_et_al_2015}}

\textit{Objectives}: Develop a model to capture the relation between passenger train arrival delays and various characteristics of a railway system, specifically infrastructure.

\smallskip

\textit{Timescale}: offline; short-term; long-term

\smallskip

\textit{Methodology}: First application of an SVR to TDP.  Compared an ANN and CVR. Categorical variables were converted to binary variables, trained using Levenberg-Marquardt backprop. 100 independent ANNs were trained and the outputs averaged. Considers seven variables: passenger train category, scheduled time of arrival at station, infrastructure influence defined by expert opinions (discussed later), percent of journey completed distance-wise, distance travelled, time travelled, and headway.

\smallskip

\textit{Data}:  727 passenger trains (99 long-distance, 321 regional, 307 suburban, northbound towards Belgrade. Delays recorded on a minute scale.

\smallskip

\textit{Results}: Found that scheduled time of arrival and headway are not strongly correlated with any other co-variates. SVR performed better than the ANN.

%FUZZY PETRI NETS
\subsection{Fuzzy Petri nets}

Fuzzy Petri nets (FPNs) are "modifications of classical Petri nets for dealing with imprecise, vague, or fuzzy information in knowledge based systems" \cite{liu_et_al_2017}. A Petri net is simply a directed bipartite graph, in which nodes represents transitions such as events (as bars) and places (as circles) and edges represent which places are pre- or post-conditions for transitions. PNs can be easily understood by graphical presentation.

%MILINKOVIC ET AL
\subsubsection{A fuzzy Petri net model to estimate train delays \cite{milinkovic_et_al_2013}}

\textit{Objectives}: To develop a FPN model for estimating train delays.

\smallskip

\textit{Timescale}: Offline; short-term; long-term

\smallskip

\textit{Methodology}: construct an FPN using expert knowledge to define fuzzy sets and rules. Use historical data to train an Adaptive Network Fuzzy Inference System (ANFIS). An ANFIS combines the learning ability of an ANN and the capacity of fuzzy logic to interpret imprecise data. Import this ANFIS into an FPN and test on part of the Belgrade railway network. 

\smallskip

\textit{Data}: Used data on train delays for July 2010 from part of the Belgrade railway network.  3710 trains: international passenger, domestic passenger, suburban and regional passenger, international freight, and so on. Features are train category, time of arrival at the station, the distance travelled, and the infrastructure influence (explored later). 

\smallskip

\textit{Results}: Sub-5\% accuracy for two stations, but over 10\% for two others, due to the lower number of trains and many delay outliers. Anticipates the applicability of the model to infrastructure investment decisions.

% ENSEMBLE / HYBRID METHODS
\subsection{Ensemble methods}

Ensembles use multiple models to generate predictions. The rationale behind such ensembles is simple: using a diverse set of models reduces bias and error rates.

%NAIR ET AL 2019
\subsubsection{An ensemble prediction model for train delays \cite{nair_et_al_2019}}

\textit{Objectives}: To develop a large-scale, data-driven ensemble forecasting system for train delays

\smallskip

\textit{Timescale}: Online; real-time; short-term; long-term

\smallskip

\textit{Data}: Used 3.25 years of data collected from Deutsche Bahn. Incorporated a wide range of exogenous data. Roughly 350 features for operational (i.e. running) trains, and 70 for non-operational trains, including train properties, real-time train state, network-related such as track and platform occupation conflicts, connections, and external features. 

\smallskip

\textit{Methodology}: began with extensive consultations with SMEs to arrive at a set of factors with explanatory factors. Started on 2 performance metrics; ended up with 80. Evaluated SVRs as a potential candidate for inclusion in their EM. However, they were found not to provide the best accuracy, quadratic in training data volume, and very sensitive to hyper-parameters, so selected RFs instead for the accuracy of forecasts and the possibility of incremental (updating model parameters as fresh data becomes available) and parallel training. 

Used 3 models for operational trains (those currently running): a RF ($n$-stop ahead), mesoscopic simulation and kernel regression, and a static RF for non-operational trains, and mesoscopic simulation. For kernel regression, a reference catalog of movements for each train is stored. A forecast is then generated by weighted sum, with weights computed by measuring the similarity between the train of interest and the weighted set. Only used for operational trains. A threshold-based heuristic was used to identify trains that ought to be stored. The simulation model was based on \cite{szabo_et_al_2017}. The model was run every minute, initialised using the most recent train status message. 

\smallskip

\textit{Results}: Found greatest potential for improvements is in shorter-term forecasts of operational trains. Initially scoped to do two-day ahead forecasts, but found that predictions beyond 24 hours were only marginally better than the schedule. Found an interesting edge case where trains with long delays did not report positions. 

%ONETO ET AL 2019
\subsubsection{A dynamic, interpretable, and robust hybrid data analytics system for train movements in large-scale railway networks \cite{oneto_et_al_2019}}

\textit{Objectives}: To develop the first hybrid model (HM) in the literature. Such a model is dynamic, interpretable, and robust.

\smallskip

\textit{Timescale}: Online; real-time

\smallskip

\textit{Metholodogy}: combined a experience-based model (EBM) and a RF into a hybrid model (HM), to overcome the limitations of both. The EBM is based on knowledge of the network and the experience of the operators.  Introduces the idea of a penalty cost, whereby the cost of delay is variable dependent on train type, location, type of railway section, amount of delay. Predict running time, dwell time, penalty cost, and train overtaking, and construct delay from these variables. The HM is a DT where each leaf is a RF. Trains are directed to the appropriate RF by similarity. A new leaf is added each time a new train movement is added that belongs to a previously unexplored branch of the decision tree. The RF regressor in the leaf is trained based on all the past train movements that fall in that leaf. The HM forget movements older than 3 months, based on experience of operators and different window size. Prediction is just consulting the appropriate leaf. The whole HM is constructed and updated incrementally as new train movements become available.

\smallskip

\textit{Data}: This study worked closely with RFI, the Italian railway authority. Used more than 6 months of data relating to two main areas in Italy, including more than 1000 trains and several checkpoints. The study also used weather data, discussed later. 

\smallskip

\textit{Results}: Found the HM to provide the best trade-off between accuracy and computational requirements. HM clearly outperforms the EBM and the DDM, both of which are state-of-the-art. Most evident for freight and regional trains. Constantly better across the whole year. Reaches optimal accuracy after 10 days of results. Handles infrequent events well. 

% EXTREME LEARNING MACHINES
\subsection{Extreme learning machines}

ELMs are feedforward neural networks. They were introduced to overcome problems posed by backprop, namely "slow convergence rates, critical tuning of optimisation parameters, and presence of local minima necessitating multi-start and re-training strategies" \cite{oneto_et_al_2017a}.

%ONETO ET AL 2017
\subsubsection{Train Delay Prediction Systems: A Big Data Analytics Perspective \cite{oneto_et_al_2017a}}

\textit{Objectives}: to build a data-driven TDP system for large-scale railway networks that exploits the most recent big data technologies, learning algorithms, and statistical tools. 

\smallskip

\textit{Timescale}: online; real-time

\smallskip

\textit{Methodology}: Used Apache Spark in-memory technology. Explores the application of a both a shallow ELM (SELM) and a deep ELM (DELM). Uses 10-Fold Cross Validation to tune hyperparameters. For every train, DELM and SELM models were built, tuned. applied, and finally validated based on actual future data. 

\smallskip

\textit{Data}: 6 months, from January 2016 to June 2016, of train movements records from the entire Italian railway network.

\smallskip

\textit{Results}: DELM is up to 200\% more performant than the current system in use. SELM all shows improvements. but not to the same extent. For DELM, a deep architecture with a small number of neurons in each layer is preferred.

%ONETO ET AL 2017b (thresholdout)
\subsubsection{Dynamic Delay Predictions for Large-Scale Railway Networks: Deep and Shallow Extreme Learning Machines Tuned via Thresholdout \cite{oneto_et_al_2017b}}

\textit{Objectives}: To develop a dynamic data-driven TDP system that allows exploiting both historical data about train movements and exogenous data about the weather. 

\smallskip

\textit{Timescale}: Online; real-time

\smallskip

\textit{Methodology}: Used Apache Spark in-memory technology. Explores the application of a both a shallow ELM (SELM) and a deep ELM (DELM). For every train, DELM and SELM models were built, tuned. applied, and finally validated based on actual future data. Uses the thresholdout procedure to optimise the hyperparameters of SELM and DELM.

\smallskip

\textit{Data}: 6 months, from January 2016 to June 2016, of train movements records from the entire Italian railway network, and weather data covering the region. 

\smallskip

\textit{Results}: DELM tuned via thresholdout is the best performing model, with up to 2x better accuracy that then current RFI model, and superior performance to DELM tuned via the standard hold out method (cross validation). 

%Pongnumkul: worked on data-driven models for TD predictions, treating the problem as a time series forecast one. System was based on autoregressive integrated moving average and nearest neighbour models. 

% MARKOV MODELS
\subsection{Markov models}

A Markov chain is a stochastic model that describes a sequence of possible events. The probability of each event depends only on the state attained in the previous event.
Such models, then, are likely too simplistic for predicting knock-on delays

% GAURAV ET AL 2018
\subsubsection{Estimating Train Delays in a Large Rail Network using a Zero Shot Markov Model \cite{gaurav_et_al_2018}}

\textit{Objectives}: To develop a scalable, train-agnostic, and Zero-Shot competent framework for predicting train arrival delays

\smallskip

\textit{Timescale}: Offline; short-term; long-term

\smallskip

\textit{Methodology}: studies systemic delays in train arrivals using $n$-order Markov frameworks. Used RF regressors and ridge regressors. Avoided building train-specific models for real-time deployment and scalability. RF had 231 trees.

\smallskip

\textit{Data}: Uses train operations data for the past two years. Only a small dataset: 135 trains between March 2016 and February 2018, at single station in India. 

\smallskip

\textit{Results}: RF regression was found to be superior than MLR: approximately 80\% of instances had a absolute error or $< 1$ minute. Using just 1.2\% of trains in India, was able to covert more than 11.3\% of stations

% EXOGENOUS DATA
\clearpage
\section{Exogenous data}

It is widely accepted in ML that the greater the quantity of information available for the creation of a model, the greater the performance of that model will be. Features can either be \textit{engineered} from existing data or incorporated from \textit{exogenous} data. Data is exogenous if it is independent of other input data but the output data is dependent on it. The scope for inclusion is essentially limitless: any source of data which may affect railway operations is a viable candidate. This section explores the use of exogenous data in the selected studies according to the classification defined previously: weather, infrastructure, maintenance, and "other".

% WEATHER
\subsection{Weather}

Weather data is the most popular candidate for inclusion. It was first used in a TDP model, to the best of the authors' knowledge, in \cite{oneto_et_al_2016}. It is expected that weather-induced delays are seasonal, with heat causing delays in summer, rain and leaves causing delays in autumn, and snow and ice causing delays in winter: \cite{brazil_2017} found that most weather-caused delays occurred in the last third of the year, with a peak in November. It is therefore important that models be trained with at least a year's worth of data: \cite{wang_et_al_2019} partly attribute the poor performance of their model to the short duration (1 January 2019 - 31 March 2019) of data collection. 

There is also, naturally, a geographical element to the influence of weather on train delays: more temperate climes are likely to have less extreme weather, and so fewer delays due to that weather. \cite{wang_et_al_2019} observed that in locations less prepared for specific types of severe weather - such as snowy weather in southern cities - delays were greater. They found that in severe weather train delays are determined mainly by the type of bad weather. \cite{oneto_et_al_2016} note that weather conditions can additionally influence passenger flow and consequently dwell times, which have already been described as a key influence on delays. Typically, each location from which train data is reported is mapped to a geographically close weather observation station.

Resolution is also important. Hourly data, as might be expected, improves the performance of a model \cite{nabian_et_al_2019}\cite{wang_et_al_2019}.

The fields used are fairly heterogeneous: maximum, minimum, and average temperature; some weather type category (e.g. cloudy; overcast; thunderstorm); wind speed; wind direction; and precipitation. More unusual fields include pressure \cite{oneto_et_al_2016}\cite{oneto_et_al_2017b}\cite{oneto_et_al_2019}, air quality \cite{wang_et_al_2019}.

\cite{oneto_et_al_2016} found that the inclusion of weather data improved the accuracy of their RF model by approximately 10\%, with the caveat that the further ahead in the future the forecast is (and thus the less accurate), the smaller this increase was. However, \cite{nair_et_al_2019} found that weather has only a small impact on delays; an analysis of delay attribution data showed that less than 3\% of delays were directly attributed to weather. 

%INFRASTRUCTURE

\subsection{Infrastructure}

Infrastructure is the second most popular candidate for inclusion.  It is a thoroughly modelled in the analytical models for TDP.

Of the four papers to include infrastructure data, two use expert opinions to assign a score to track sections \cite{milinkovic_et_al_2013} \cite{markovic_et_al_2015} and two use the data directly \cite{barbour_et_al_2018} \cite{nair_et_al_2019}.

In the former two, opinions are collected from traffic dispatchers, operators, and subject matter experts. Each line or section considered is assigned a score based on characteristics such as the number of tracks, the percentage of rail on which trains must travel at reduced speeds, the number of stations, stops, loops, level crossings, junctions, length, block section, track clear section (station distance, braking distance, automatic block system, centralised traffic control, axle counters, and so on. 

The Delphi method is used to produce a single output score. The obvious limitation of this method is that each section must be independently human-assessed; in rail networks thousands of kilometres in length, this is clearly impractical.  In \cite{markovic_et_al_2015}, only 39 lines were evaluated. A score of 1 in denotes a route with the highest number of infrastructural factors that could cause unplanned delays. The study found a strong correlation between expert opinions and train delays. 

\cite{barbour_et_al_2018} takes into account individual tracks, switches, mileposts, and terminals, in order to build a network graph describing single-track edges, multi-track edges, and single-track edges with sidings. 



 single-tracking, reduced speeds, characteristics of block and interlocking systems, number of stations, stops, loops, road-rail level crossings, and junctions


\cite{milinkovic_et_al_2013} groups infrastructure opinions. Collected opinions from traffic dispatchers, operators, and experts famiilar with the functioning of the system. Was used more broadly to define input variables, and the primary causes of delay (not the causes of primary delay). Defined three input parameters: the train category, timetable influence, and the distance travelled by the train. Timetable influence was used as a catch-all of sorts; the study is vague on specifics. It included the influence of infrastructure parameters, timetable characteristics, operation time, the type of locomotive, local conditions, technological solutions, principles for safety and signalling, and weather conditions. This is for the FPN!

For the ANFIS, which used real-life data (go into detail here), an 'infrastructure influence', which included the percentage of restricted speed sections, the number of junctions, and the number of stations). Included section length, section plans, restricted speed, and track routes. 

\cite{nair_et_al_2019} take exactly this approach. The authors reconstruct the network and estimate capacity directly from passing messages. Furthermore, the method used generated train-class specific networks. The inferred method is employed for various downstream tasks: inferring train paths, conflict status estimation, typical travel time estimation. "Passing" messages are sorted by date, time, and train. If there are sufficient observations, the control point and track stretch is recorded as an edge. The frequency of transitions from each outgoing edge, the mean and standard deviation of travel times are also recorded for each edge. A feasibility matrix for each outgoing edge is recorded at each vertex, which records pairwise edge feasible flows at each section by identifying movements by two trains in a short time window; this is used to identify potential conflicts between trains when there are deviations from the schedule. Reconstructed networks around several major hubs were inspected by hand and found to be accurate. 

Station attributes used included the designated platform, station attributes, historical mean delay at tracks, platforms, actual platform, track allocation, and track / platform change status.

% Maintenance

\subsection{Maintenance}

\cite{nair_et_al_2019} used work zone information, indicating location, duration, and the likely impact on different train categories.

% Other

\subsection{Other}

No papers were found to incorporate accidents, vandalism, trespassing, fatalities, or strikes. Holidays are, however, included in \cite{nair_et_al_2019}\cite{oneto_et_al_2017b}.

% EVALUATION
\clearpage
\section{Evaluation}

\subsection{RQ1: What ML models are commonly used for TDP?}

A wide variety of ML models have been applied for TDP. Interest in the area has only really developed in the past decade, and as ML theory has developed so quickly in this time, many such models have become outdated even in this short timeframe. 
Neural networks make only a brief appearance in \cite{yaghini_et_al_2013}, though they are often used as a benchmark to compare more sophisticated models against.
Popular models such as support vector regression (SVR) and support vector machines (SVM) are applied in \cite{markovic_et_al_2015} \cite{barbour_et_al_2018}. Markov models are also used, but only in limited contexts, in \cite{gaurav_et_al_2018}.

More esoteric ML models, such as fuzzy Petri nets, are also used in \cite{milinkovic_et_al_2013}, although without further development.

Currently at the forefront of research are three models: random forests \cite{oneto_et_al_2016}\cite{nabian_et_al_2019}\cite{nair_et_al_2019}, Bayesian networks \cite{lessan_fu_wen_2019}\cite{corman_kecman_2018} and extreme learning machines \cite{oneto_et_al_2017a}\cite{oneto_et_al_2017b}. Increasingly, these models are combined into an ensemble or hybrid model, as in \cite{nair_et_al_2019} (random forests, kernel regression, and mesoscopic simulation) \cite{oneto_et_al_2019} (random forests, experienced-based model).

For the authors' own work, the methodology and model structure described in \cite{nair_et_al_2019} is deemed most suitable for replication, with scope limited to the real-time: the approach is state-of-the-art, thoroughly described, and uses data very similar to that available to that of the author. Additionally, their models are entirely data-driven, and so do not require a close working relationship with a railway manager to define the rules of an experience-based model as used in \cite{oneto_et_al_2019}.

\subsection{RQ2: What exogenous data is used to improve the performance of those models?}

A four-way classification was defined early for exogenous data: weather, infrastructure, maintenance, and 'other'. 

Weather was first used in \cite{oneto_et_al_2016}, and has subsequently been investigated in \cite{brazil_2017} and applied in \cite{wang_et_al_2019}\cite{nair_et_al_2019}\cite{nabian_et_al_2019}. \cite{oneto_et_al_2016} found 10\% performance increase when incorporating weather data into their RF model. However, \cite{nair_et_al_2019} cast doubt on the effect of weather: only 3\% of delays in their dataset were directly attributable to weather. The authors plan to do their own statistical analysis of delay attribution records. 

Infrastructure is the next most popular. \cite{milinkovic_et_al_2013} and \cite{markovic_et_al_2015} both use the expert opinions of dispatchers to construct a variable describing the effect of various infrastructure features along a rail line (single-tracking, reduced speeds, characteristics of block and interlocking systems, number of stations, stops, loops, road-rail level crossings, and junctions, etc.) on the likelihood of the delays on that line. Both (unsurprisingly) find a strong correlation between this score and severity of delays.

\cite{nair_et_al_2019} take a more programmatic approach and reverse engineer characteristics such as capacity and network structure directly from their dataset.

The authors think that infrastructure has been somewhat neglected. Perhaps, however, describing it as "exogenous" is disingenuous here: many models use some descriptor of the rail network as an input, or at least characteristic.

The authors will use the approach of \cite{nair_et_al_2019} or an existing data-set (if they can finally fucking parse it)!

Maintenance is used only by \cite{nair_et_al_2019}, who quite rightfully claim to have constructed the most comprehensive dataset yet for TDP. The authors will also use historical data of maintenance work.

As we continue, the factors becomes less important, and perhaps less predictable. "Other" is very much a catch-all. It contains events that likely cannot be predicted (e.g. accidents, vandalism, trespassing, fatalities) due to insufficient data and fairly menial features: holidays and the like.

Of these categories, the authors will include holidays and strikes. NR categorises the day by weekday, Saturday, Sunday, Christmas, and Bank holiday, reflecting the different timetables used for each.


% There's no equivalent of a "commonly used dataset", unfortunately. What were the RQs for the first systematic 

% file:///C:/Users/user/Downloads/EuroMaintenance2016_Full_Paper_IDCv1%20(1).pdf: notes on data fusion of NR's assets.


\subsection{RQ3: What are the current research areas of TDP?}



This has perhaps been the hardest RQ to answer. Only one data point is available. \cite{oneto_et_al_2019} note that, since their earlier paper \cite{oneto_et_al_2016}, RFI, the Italian railway manager, has adopted their model and a experience-based models similar to that described in \cite{hansen_goverde_van_der_meer_2010}. It seems clear the the future of TDP is ML, not analytical.

It is also noted in \cite{oneto_et_al_2016} that RFI use a system similar to \cite{hansen_goverde_van_der_meer_2010}, which lends credence to their suggestion that most extant TDP systems are analytical.

Incorporating delay attribution into the model as part of the issue. Currently there's an extensive and complicated model. 

Noted also by \cite{nair_et_al_2019}: that different categories of trains need different models. 
Incorporating delay attribution back into it. 


%Data-driven methods may not extrapolate well to rare and extreme events such as heavy network disruptions, especially when few or no examples exist in the training data \cite{barbour_et_al_2018}.
%Trains are heterogenous in respect in tonnage, power, length, and priority. 

\cite{oneto_et_al_2019}, in their hybrid model, have essentially a RF for categories of trains.


%\textit{Limitations}: Amtrak shares track with freight trains, but freight train position data is not publicly available, and so the knock-on delay caused by freight traffic could not be captured. Regression model could not be constructed for all trains as they were subject to a route re-configuration, and so a complete set of training / test data is not available.  (WANG and WORK)


% Future work will take in account also exogenous data from external sources such as weather information, information about passenger flows using touristic databases, and about railway asset conditions \cite{oneto_et_al_2017a}.

% Limitations: the target variable (delay distributions) varies considerably based on time horizon, train types, service classes, and current delay. One set of methods is unlikely to perform well across all categories.
% nair et al 2019

% https://www.railengineer.co.uk/2011/09/06/real-time-rail-passenger-information-jungle-or-minefield/


% I didn't choose to be born me any more than you did
% brooded. Anything ending in -ded.
% brooding / alluding
% prognosticate (tell a prophecy)

\section{Conclusion}

We performed a systematic literature review for applications of machine learning in train delay prediction. A wide variety of studies and models have been discussed. We have thoroughly investigated exogenous data used to improve the performance of these models, and have identified a paper suitable for replication with the data available to the authors.

\printbibliography
 
\end{document}