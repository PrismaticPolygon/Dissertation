\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{titling}
\usepackage[backend=biber, style=numeric]{biblatex}
\usepackage[margin=0.5in]{geometry}
\usepackage{multicol}

\bibliography{review}

\title{A systematic literature review of machine learning models for train delay prediction}
\author{D. White, N. Al-Moubayed}
\date{\today}

\begin{document}
\begin{titlingpage}

\maketitle
\begin{abstract}

\textit{Context}: Train delays impose a huge cost on both train operators and passengers. Train delay prediction (TDP), the forecasting of delays, allows the preemptive rescheduling or re-routing of crews and rolling stock, increases the information available to passengers, results in more efficient utilisation of operational capacity, and reduces cost.
Most TDP systems in use are analytical, but data-driven machine learning (ML) models are increasingly popular in the literature, and offer superior performance. 

\smallskip

\textit{Objective}: the goal of this work is to synthesise available research results to identify currently used ML models, the exogenous data used to improve the performance of those models, and current research areas in the TPD. 

\smallskip

\textit{Method}: studies about the application of ML models to TPD were gathered via a systematic literature review. 

\smallskip

\textit{Results}: 19 studies were selected. 9 distinct models are used: artificial neural networks, fuzzy Petri nets, Markov chains, regression, Bayesian networks, ensembles, extreme learning machines, support vector regression, and random forests.
The methodologies, data, and results of each study are evaluated. Of the models identified, ensembles offer the best performance, with random forests as sub-models. Weather and infrastructure data is commonly used to improve performance, but there is scope for inclusion of other datasets, such as passenger volume. 
Future research areas are identified.

\smallskip

\textit{Conclusion}: The selected studies present a range of models. Those that compare results to existing analytical systems find ML models to be superior. The inclusion of exogenous data is observed to improve performance.
We propose an ensemble composed of ML models, trained on data from the UK rail network. 

\end{abstract}
\end{titlingpage}

\tableofcontents
\clearpage

\section{Introduction}

\subsection{Delays}

A \textit{delay} is a "positive deviation between the realized time and scheduled times of [an] activity" \cite{cerreto_nielsen_harrod_nielsen_2016}. In this case, the activity is either the departure or arrival of a train.  Although precise terminology differs, the literature agrees that there are two principal classes of delay \cite{olsson_haugland_2004}: primary and secondary.

\subsubsection{Primary delays}

A \textit{primary} or \textit{exogenous} delay is "caused by external stochastic disturbances" \cite{oneto_et_al_2016}. The causes of primary delays are varied and numerous \cite{berger_et_al_2011}\cite{cerreto_nielsen_harrod_nielsen_2016}\cite{milinkovic_et_al_2013}\cite{nr_delay_causes} and many different classifications exist. For the purposes of this dissertation, the following classification is proposed:

\begin{itemize}
	\item \textit{Weather}: severe heat, flooding, landslips, leaves, snow, and ice
	\item \textit{Passenger}: prolonged alighting and boarding times
	\item \textit{Maintenance}: construction work, repair work
	\item \textit{Other}: accidents, vandalism, trespassing, fatalities, strikes, holidays
\end{itemize}

A large component of this dissertation is the effect of the inclusion of exogenous data on the predictive capability of various machine learning techniques: this classification broadly follows the datasets that will
be considered.

\subsubsection{Secondary delays}

A \textit{secondary} (\textit{knock-on}, \textit{consecutive}) delay is "generated by operations conflicts" \cite{cerreto_nielsen_harrod_nielsen_2016}, i.e. primary delays. Secondary delays often affect
both the route on which the primary delay occurred and any connecting routes; delays 'cascade' as "trains, drivers, and crews aren't in the right place at the right time to run other services" \cite{nr_knock_on_delays},
or as trains are held according to waiting policies \cite{berger_et_al_2011}. Secondary delays cannot be exactly forecast \cite{berger_et_al_2011}\cite{milinkovic_et_al_2013} because they are influenced by multiple interacting factors: the severity of the primary delay, the timetable of the train, infrastructure, and even the behaviour of the driver, for example. 

\subsection{Timescales}

TPD models are either \textit{online}, in which they are dynamically updated with new data as it becomes available, or \textit{offline}. Models can be further subdivided into whether they are used to predict train delays in real-time, or in the future, though this is not a perfect delineation: \cite{nair_et_al_2019} merges these categories in an ensemble by utilising different underlying models.   Real-time models are by necessity online, and make up the majority of TDP systems.

Future models can be further broken down into short-term and long-term. Long-term "tactical" \cite{markovic_et_al_2015} models are used for timetabling and resource planning. Short-term models are relatively rare, and are typically constrained by features which can only be forecast up to a limit, such as weather, as in \cite{nair_et_al_2019}\cite{wang_et_al_2019}.

\subsection{Metrics}

Two key metrics are used to measure delays, and more broadly, performance: punctuality and reliability. 

\subsubsection{Punctuality}

\textit{Punctuality} is "a feature consisting in that a predefined vehicle arrives, departs, or passes at a predefined point at a predefined time" \cite{rudnicki_1997}. This definition has the interesting effect that trains 
that arrive \textit{early} cannot be considered punctual. However, the use of punctuality hides a lot of information \cite{skagestad_2004}; reliability and variability are better metrics \cite{olsson_haugland_2004}. As variability is infrequently used, it is disregarded here. The Office of Road and Rail (ORR), the UK's railway regulator, uses Public Performance Measure (PPM) to assess punctuality.

\subsubsection{Reliability}

\textit{Reliability} has several measures \cite{rietveld_bruinsma_van_vuuren_2001}: typically, it is taken it taken to be the probability that a train arrives $x$ minutes late (i.e. is punctual). ORR uses Cancellations and Significant Lateness (CaSL) to assess reliability.

% OVERVIEW OF SYSTEMATIC LITERATURE REVIEW METHOD
\clearpage
\section{Overview of systematic literature review method}

A systematic literature review (SLR) is "a means of evaluating and interpreting all available research relevant to a particular research question or topic area or phenomenon of interest" \cite{williams_hollingsworth_2005}. The research questions that this SLR are intended to answer are:

\begin{itemize}
	\item RQ1: What ML models are commonly used for TDP?
	\item RQ2: What exogenous data is used to improve the performance of those models?
	\item RQ3: What are the current research areas of TDP?
\end{itemize}

The SLR was based on a recent literature review \cite{ghofrani_et_al_2018}, the methodology of which is discussed thoroughly below. The studies identified in \cite{ghofrani_et_al_2018} are used to select key search terms for further database queries. Additionally, the cited references of those studies were used to find other relevant papers. These studies are then selected for inclusion in this review by title, abstract, and finally by content on their relevance to the application of ML to TDP.

\subsection{Recent applications of big data analytics in railway transportation systems: A survey \cite{ghofrani_et_al_2018}}

Only an overview of the content relevant to this literature review is presented here.
The authors identified the following data-related keywords and railway transportation system (RTS) -related keywords for a database search. Of particular significance here is "Railway Operations", which covers the actual \textit{running} of trains on a RTS, and therefore delays. The authors limited the scope of their search to papers in scientific journals, conferences, and dissertations in English from the last 15 years (i.e. 2003 - 2017). They specifically included only papers with quantitative results. They searched ScienceDirect, Emeralds, Scopus, EBSCO, and IEEE Xplore, and also used cited references of studied papers as a source. 115 papers were found and were classified by a four-layer structure:

\begin{enumerate}
	\item Area of RTS: Maintenance, Operations, Safety
	\item Analytic category: descriptive, predictive, prescriptive
	\item BDA model: clustering, numeric prediction, association, statistical analysis, image processing, and so on.
	\item Implementation technique: Bayesian network, SVM, SVR, Decision Tree, ANN, Regression
\end{enumerate}

We are interested in Operations; papers in the other areas are disregarded. Within Operations, the authors discuss the applications of BDA to RTS, data collection and sources in RTS, and finally the studies themselves.
Only those that focus on TPD are considered. In total, 19 papers were selected by title for inclusion in this literature review; they provided the foundation for a subsequent database search.

\subsection{Database search}

The papers selected from \cite{ghofrani_et_al_2018} were used to identify the following key search terms: "train", "delay" and "prediction". Alas, "train" is a common word in scientific literature, and this confounded initial results. Appropriate synonyms were identified for each term. The following databases, based on those used by \cite{heckman_williams_2011}, were searched:

\begin{multicols}{2}

\begin{itemize}
	\item ACM Digital Library
	\item IEEE Xplore
	\item ScienceDirect
	\item SpringerLink
\end{itemize}

\end{multicols}

Where possible, the discipline was restricted to Computer Science. Approximately 3000 studies were identified; some post-processing was necessary to reduce the number of studies retrieved. In total, 69 studies were selected.

%ScienceDirect yielded 73 articles, of which 44 were selected by title. 
%SpringerLink yielded 119 articles, of which 11 were selected by title.
%ACM yielded 9 articles, of which 5 were selected by title.
%IEEE Explore yield 22 articles, of which 9 were selected by title.

\subsection{Study selection}

Study selection was a three-stage process:

\begin{enumerate}
	\item Initial selection by title
	\item Selection by abstract
	\item Further selection by content
\end{enumerate}

Of the 88 total studies found, 5 were duplicates. 64 studies were excluded by extract, and 8 by content. 4 studies were discovered through other means - either from a preliminary, less structured, search, or from cited references. In total, 15 relevant papers were identified.

% STUDIES
\section{Overview of studies}

We identified 15 studies in the literature that focus on the application of ML to TPD. A preliminary analysis shows that all work occurred in the past decade (i.e. during, or after, 2010), with most studies (53\%) published in 2018 and 2019.

\begin{table}[ht]
\centering
\begin{tabular}{ll}
\noalign{\smallskip}\hline \noalign{\smallskip}
Year & \# \\	\noalign{\smallskip}\hline \noalign{\smallskip}
2013 & 2 \\
2015 & 2 \\
2016 & 1 \\
2017 & 2 \\
2018 & 4 \\
2019 & 4 \\ \noalign{\smallskip}
Total & 15 \\ \noalign{\smallskip}\hline
\end{tabular}

\begin{tabular}{lll}
\noalign{\smallskip}\hline \noalign{\smallskip}
ML model & Acronym & \# \\ \noalign{\smallskip}\hline \noalign{\smallskip}
Artificial neural network & ANN & 1 \\
Fuzzy Petri net & FPN & 1 \\
Markov chains &  & 1 \\
Regression &  & 1 \\
Bayesian network & BN & 2 \\
Ensemble &  & 2 \\
Extreme learning machine & ELM & 2 \\
Support vector regression & SVR & 2 \\
Random forest & RF & 3 \\ \noalign{\smallskip}\hline \noalign{\smallskip}
Total &  & 15 \\ \noalign{\smallskip} \hline
\end{tabular}
\end{table}

9 distinct ML models were identified. Several papers compared and contrasted different models; in this scenario, the model the authors found to be superior is chosen. In this case that different variations of the same model were tested, they are grouped under their lowest common denominator. Two studies \cite{nair_et_al_2019}\cite{oneto_et_al_2019} used ensembles, a model composed of multiple models; rather than count each sub-model separately, they are classified as 'ensembles'. The most popular techniques are random forests (20\%), followed by ensembles (13\%), extreme learning machines (13\%), and support vector regression (13\%).

\section{ML models}

In this section, each of the distinct ML models identified previously is discussed. 

% NEURAL NETWORKS
\subsection{Neural networks}

Neural networks are models based on human brains. The oldest application of ML to the general problem of predicting delays in public transport that the authors are aware of used a NN \cite{peters_et_al_2005}.  This study was not selected for inclusion in this review, however. The popularity of neural network has declined in recent years as more sophisticated models have been developed; they are primarily used as a benchmark in the studies selected for this review. 

%YAGHINI ET AL 2013
\subsubsection{Railway passenger train delay prediction via neural network model \cite{yaghini_et_al_2013}}

\textit{Objectives}: To develop a high-precision neural network model to predict the late arrival of passenger trains in Iran.

\smallskip

\textit{Timescale}: Offline; real-time; short-term; long-term

\smallskip

\textit{Data}: Data from 2005 to the end of 2009 is used. This comprises approximately 180,000 passenger trains, with a total delay of approximately 5.5 million minutes. Stopping time at interval stations (i.e. dwell time) for praying, boarding, and alighting are excluded from delay time.  

\smallskip

\textit{Methodology}: Compares three different input methods (normalised real number, binary coding, and binary set encoding) for a neural network model. Used decision trees and multiple logistic regression to evaluate the quality of results. Also compared three different architectures: quick, dynamic, and multiple. Quick trains a single network; dynamic adds nodes until a specified level of performance is reached; multiple trains networks in parallel and selects the most accurate. 

\smallskip

\textit{Results}: The accuracy level of the binary quick model was found to be superior to other statistical models such as decision tree and multinomial logistic regression models, though with significantly longer training time.

%FUZZY PETRI NETS
\subsection{Fuzzy Petri nets}

Fuzzy Petri nets (FPNs) are "modifications of classical Petri nets for dealing with imprecise, vague, or fuzzy information in knowledge based systems" \cite{liu_et_al_2017}. A Petri net is simply a directed bipartite graph, in which nodes represents transitions such as events (as bars) and places (as circles) and edges represent which places are pre- or post-conditions for transitions. PNs are easily interpretable. 

%MILINKOVIC ET AL
\subsubsection{A fuzzy Petri net model to estimate train delays \cite{milinkovic_et_al_2013}}

\textit{Objectives}: To develop a FPN model for estimating train delays.

\smallskip

\textit{Timescale}: Offline; short-term; long-term

\smallskip

\textit{Methodology}: construct an FPN using expert knowledge to define fuzzy sets and rules. Use historical data to train an Adaptive Network Fuzzy Inference System (ANFIS). An ANFIS combines the learning ability of an ANN and the capacity of fuzzy logic to interpret imprecise data. Import this ANFIS into an FPN and test on part of the Belgrade railway network. 

\smallskip

\textit{Data}: Used data on train delays for July 2010 from part of the Belgrade railway network.  3710 trains: international passenger, domestic passenger, suburban and regional passenger, international freight, and so on. Features are train category, time of arrival at the station, the distance travelled, and the infrastructure influence (explored later). 

\smallskip

\textit{Results}: Sub-5\% accuracy for two stations, but over 10\% for two others, due to the lower number of trains and many delay outliers. Anticipates the applicability of the model to infrastructure investment decisions.

% MARKOV MODELS
\subsection{Markov models}

A Markov chain is a stochastic model that describes a sequence of possible events. The probability of each event depends only on the state attained in the previous event.

% GAURAV ET AL 2018
\subsubsection{Estimating Train Delays in a Large Rail Network using a Zero Shot Markov Model \cite{gaurav_et_al_2018}}

\textit{Objectives}: To develop a scalable, train-agnostic, and Zero-Shot competent framework for predicting train arrival delays

\smallskip

\textit{Timescale}: Offline; short-term; long-term

\smallskip

\textit{Methodology}: studies systemic delays in train arrivals using $n$-order Markov frameworks. Used RF regressors and ridge regressors. Avoided building train-specific models for real-time deployment and scalability. RF had 231 trees.

\smallskip

\textit{Data}: Uses train operations data for the past two years. Only a small dataset: 135 trains between March 2016 and February 2018, at single station in India. 

\smallskip

\textit{Results}: RF regression was found to be superior than multiple linear regression: approximately 80\% of instances had a absolute error or $< 1$ minute. Using just 1.2\% of trains in India, was able to covert more than 11.3\% of stations

% REGRESSION
\subsection{Regression}

Regression is used to construct a relationship between two or more explanatory variables (independent) and a response (dependent) variable by fitting a linear equation to the data. While simple, it forms the basis for many other ML models.

%WANG AND WORK 2015
\subsubsection{Data driven approaches for passenger train delay estimation \cite{wang_work_2015}}

\textit{Objectives}: To develop a historical regression model to estimate future trains delays using only the past performance of a train along a given route.

\smallskip

\textit{Timescale}: offline; online; real-time; short-term

\smallskip

\textit{Methodology}: developed four regression models, one offline, three online, to predict train delays. Assumes that delays from one trip to the next follow a vector autoregressive process. Assumption is valid because passenger trains operate on a fixed frequency (daily) and schedule, and so prior delays on previous trips hold information to estimate the train delay at each station for the current trip. The vector autoregressive process predicts train delays at each station along the route simultaneously. Determines parameters of regression model through least squares estimation on the training dataset.

\smallskip

\textit{Data}: Data is from 282 Amtrak trains from 2006 – 2013, more than 100,000 train trips. Amtrak trains have operational priority yet the on-time rate of Amtrak is less than 50\%. Average delay for several trains can reach as high as 50 minutes. Coarse; lots of missing records. 

\smallskip

\textit{Results}: Historical regression models improves the RMSE estimate of delay by 12\%. The online proposed model improves the RMSE estimate of delay by 60\%.

% BAYESIAN NETWORKS
\subsection{Bayesian networks}

A Bayesian network (BN) is a "probabilistic graphical model that uses Bayesian inference for probability computations" \cite{towards_data_science_BN_intro}. Each directed edge models a conditional independence, allowing "the incorporation of massive historical data" \cite{lessan_fu_wen_2019}. BNs allow the updating of probability distributions and reduce the uncertainty of future train delays in real-time as more data continuously comes available from the monitoring system \cite{corman_kecman_2018}.

% CORMAN AND KECMAN, 2018
\subsubsection{Stochastic prediction of train delays in real-time using Bayesian networks \cite{corman_kecman_2018}}

\textit{Objectives}: To examine the effect that the prediction horizon and incoming information about a running train may have on the predictability of subsequent arrival and departure times of all trains. To answer the question: how does the prediction of a single delay event change over time as the same event approaches the time \textit{now}?

\smallskip

\textit{Timescale}: online; real-time

\smallskip

\textit{Methodology}: Developed a stochastic model for predicting the propagation of train delays based on BNs. Extended by modelling the interdependence between trains that share the same infrastructure or a scheduled passenger transfer (i.e. a connection).

\smallskip

\textit{Data}: The model was tested on a 180km double-track mixed traffic line between Stockholm and Norrkoping, in Sweden. 90\% of traffic is passenger trains. The line comprises 27 stations and junctions; 10 of these accommodate scheduled stops of passenger and freight trains. Approximately 300 trains per day traverse the corridor. Two months' worth of data, 1 January - 28 February 2015, was gathered from the Swedish infrastructure manager Trafikverket. The punctuality performance of the dataset is within 0.4\% of the average performance for the whole of 2015. No strong seasonaility effect is present in the performance of the Swedish network. All event times are rounded to full minutes. Their database comprises the scheduled and realised times for departures, arrivals, and through runs for all trains and stations. 

\smallskip

\textit{Results}: accuracy of predictions is significantly increased within the 30-minute prediction horizon. Median error increases very slowly. S.D of the probability of an occurrence of an event, as predicted half an hour ahead of time, is 2 minutes. Major contribution is the representation of delays due to interactions between trains. 

% LESSAN ET AL, 2019
\subsubsection{A hybrid Bayesian network model for predicting delays in train operations \cite{lessan_fu_wen_2019}}

\textit{Objectives}: To identify which BN architectures are most valid / reliable for predicting train delays for a particular network structure. To develop the first hybrid BN-based prediction model in the literature.

\smallskip

\textit{Timescale}: offline; short-term; long-term

\smallskip

\textit{Methodology}: Compared three different BN schemes: heuristic hill-climbing, primitive linear, and hybrid. The data is used to rationalise the dependency graph of the BNs. Each is then trained with $k$-fold cross validation to avoid over-fitting and to evaluate performance. The hybrid BN is based on the structure from the former two schemes, and subsequently refined using domain knowledge and expert judgements about the sequences of stations and the relationships between consecutive train operations. This structure is intended to differentiate between the delay propagated from upstream operations and that due to the most recently performed operation in the prediction process. Continuous variables were discretised; specifically, 3 minutes was used as a width for prediction intervals (as late arrivals of less than 90s are not considered delays).

\smallskip

\textit{Data}: Data comes from train operations on the Wuhan-Guangzhou (WH-GZ) high-speed rail (HSR) line in China. The line is 1096km long, with 18 stations. Only 15 stations and 14 sections were used due to jurisdiction. Data was collected between February 2015 to November 2015, comprising approximately 380,000 arrival and departure events between stations on the specified line, excluding early arrivals and departures.

\smallskip

\textit{Results}: The reconstructed hybrid heuristic BN was found to perform the best out of the three, with an 80\% prediction accuracy within a 60-minute horizon, a MAE of 30s, a RMSE of less than two minutes (suggesting the presence of outlier prediction errors). The model had a no-information rate of 58\%, and a sensitivity of $>60\%$. Model is simple, interpretable, and computationally efficient. They also note that prediction errors soon accumulate, and that this could be addressed using an online model, as in \cite{corman_kecman_2018}.

% RANDOM FORESTS
\subsection{Random forests}
 
Random forests were first introduced by \cite{ho_1995}. A random forest is a collection of individual decision trees.Each individual tree predicts the class of an input and the class with the most votes is the output of the model. This improves accuracy and reduces overfitting. Decision trees in which the target variable can take a discrete set of values are called classification trees; those that take continuous variables, regression trees. Leaves represent class labels and branches conjunctions of feature that lead to that class. Accuracy depends on the number of trees composing the forest,  the accuracy of each tree, and the correlation between them \cite{breiman_2001}. Accuracy converges to a limit as the number of trees increases, and rises as the accuracy of each tree increases and the correlation between them decreases.

%ONETO ET AL 2016
\subsubsection{Advanced Analytics for Train Delay Prediction Systems by Including Exogenous Weather Data \cite{oneto_et_al_2016}}

\textit{Objectives}: To build a data-driven train prediction system that exploits the most recent analytics tools.

\smallskip

\textit{Timescale}: online; real-time

\smallskip

\textit{Methodology}: The authors compared kernel methods, extreme learning machines, and random forests. The random forest comprised 500 trees. For each train and algorithm, a model is built. The hyperparameters of each model are tuned. The models are then applied to the current state of the trains, and finally they are validated (i.e. predictions are compared to actual future events). Notably, the authors derive a set of novel Key Performance Indicators (KPIs) to evaluate performance. Approximately 600,000 models would have to be trained daily across the whole network.

\smallskip

\textit{Data}: This study worked closely with RFI, the Italian railway authority. Used more than 6 months of data relating to two main areas in Italy, including more than 1000 trains and several checkpoints. The study also used weather data, discussed later. 

\smallskip

\textit{Results}: The RF method performed up to twice as well as the current RFI system. Including weather data increased accuracy by approximately 10\%. Both ELM and KM also improve over RFI, though not to the same extent. 

% NABIAN ET AL 2019
\subsubsection{Predicting near-Term Train Schedule Performance and Delay Using Bi-Level Random Forests \cite{nabian_et_al_2019}}

\textit{Objectives}: To predict passenger train delays in the Netherlands.

\smallskip

\textit{Timescale}: online, real-time

\smallskip

\textit{Methodology}: Develops a novel bi-level RF to solve a coupled classification-regression task: identifying \textit{whether} delays will increase, decrease, or remain constant in a fixed timeframe (20 minutes), and then predicting by how much. Assumes that delays have already occurred. Compared to linear regression, multinomial logistic regression, decision trees, $k$-NN, and SVM / SVRs. Assumes that all trains rode on a single track. Each leaf in the primary classification level is a random forest for regression for that classification.

\smallskip

\textit{Data}: Data was provided from the Netherlands' railway infrastructure manager, ProRail, between September 4 2017 and December 9 2017. Includes the planned timetable, actual historical train performance, crew schedules, rolling stock circulation, (limited) infrastructure data: the distance between consecutive stations. 10 million data points over a 13 week period. Excluded Wednesdays (which are apparently particularly busy), and delays longer than 15 minutes.

\smallskip

\textit{Results}: Found that the proposed model provides the best prediction accuracy. Constructing the model is computationally cheap.

%WANG ET AL 2019
\subsubsection{Train delay analysis and prediction based on big data fusion \cite{wang_et_al_2019}}

\textit{Objectives}: To develop a machine-learning model to predict train delays.

\smallskip

\textit{Timeframe}: online; short-term

\smallskip

\textit{Methodology}: unusual in that it focused on short-term delay prediction. Used gradient-boosted regression trees (GBRT). Model predicts delays up to 10 days in advance using weather forecasts. Used density-based clustering algorithm (DBSCAN) to identify a time interval threshold $t_epsilon$, which determines whether the delay of a train at a given station propagates to the following train.  

\smallskip

\textit{Data}: used a three-month dataset of weather, train delay, and train schedule records. The weather data is thoroughly discussed later. Data collected between 1st January to 31st March 2018.
Schedule data for 7172 railway trains was obtained. GIS for 2761 railway stations was obtained from Tencent Maps (including name, longitude, and latitude. Observed nearly 2.7 million delays over the course of three months, of which 37.4\% came from high-speed trains. 

\smallskip

\textit{Results}: In severe weather, train delays are determined mainly by the type of bad weather, but in ordinary weather train delays are determined mainly by historical delay time and the delay frequency of trains. Proposes concepts of key train delay stations and the time interval threshold. Relatively poor results due to only 3 months' worth of data.

% ENSEMBLE / HYBRID METHODS
\subsection{Ensemble methods}

Ensembles use multiple models to generate predictions. The rationale behind such ensembles is simple: using a diverse set of models reduces bias and error rates.

%ONETO ET AL 2019
\subsubsection{A dynamic, interpretable, and robust hybrid data analytics system for train movements in large-scale railway networks \cite{oneto_et_al_2019}}

\textit{Objectives}: To develop the first hybrid model (HM) in the literature. Such a model is dynamic, interpretable, and robust.

\smallskip

\textit{Timescale}: Online; real-time

\smallskip

\textit{Metholodogy}: combined a experience-based model (EBM) and a RF into a hybrid model (HM), to overcome the limitations of both. The EBM is based on knowledge of the network and the experience of the operators.  Introduces the idea of a penalty cost, whereby the cost of delay is variable dependent on train type, location, type of railway section, amount of delay. Predict running time, dwell time, penalty cost, and train overtaking, and construct delay from these variables. The HM is a DT where each leaf is a RF. Trains are directed to the appropriate RF by similarity. A new leaf is added each time a new train movement is added that belongs to a previously unexplored branch of the decision tree. The RF regressor in the leaf is trained based on all the past train movements that fall in that leaf. The HM forget movements older than 3 months, based on experience of operators and different window size. Prediction is just consulting the appropriate leaf. The whole HM is constructed and updated incrementally as new train movements become available.

\smallskip

\textit{Data}: This study worked closely with RFI, the Italian railway authority. Used more than 6 months of data relating to two main areas in Italy, including more than 1000 trains and several checkpoints. The study also used weather data, discussed later. 

\smallskip

\textit{Results}: Found the HM to provide the best trade-off between accuracy and computational requirements. HM clearly outperforms the EBM and the DDM, both of which are state-of-the-art. Most evident for freight and regional trains. Constantly better across the whole year. Reaches optimal accuracy after 10 days of results. Handles infrequent events well. 

%NAIR ET AL 2019
\subsubsection{An ensemble prediction model for train delays \cite{nair_et_al_2019}}

\textit{Objectives}: To develop a large-scale, data-driven ensemble forecasting system for train delays

\smallskip

\textit{Timescale}: Online; real-time; short-term; long-term

\smallskip

\textit{Data}: Used 3.25 years of data collected from Deutsche Bahn. Incorporated a wide range of exogenous data. Roughly 350 features for operational (i.e. running) trains, and 70 for non-operational trains, including train properties, real-time train state, network-related such as track and platform occupation conflicts, connections, and external features. 

\smallskip

\textit{Methodology}: began with extensive consultations with SMEs to arrive at a set of factors with explanatory factors. Started on 2 performance metrics; ended up with 80. Evaluated SVRs as a potential candidate for inclusion in their EM. However, they were found not to provide the best accuracy, quadratic in training data volume, and very sensitive to hyper-parameters, so selected RFs instead for the accuracy of forecasts and the possibility of incremental (updating model parameters as fresh data becomes available) and parallel training. 

Used 3 models for operational trains (those currently running): a RF ($n$-stop ahead), mesoscopic simulation and kernel regression, and two models non-operational trains: a static RF and mesoscopic simulation. For kernel regression, a reference catalog of movements for each train is stored. A forecast is then generated by weighted sum, with weights computed by measuring the similarity between the train of interest and the weighted set. Only used for operational trains. A threshold-based heuristic was used to identify trains that ought to be stored. The simulation model was based on \cite{szabo_et_al_2017}. The model was run every minute, initialised using the most recent train status message. 

\smallskip

\textit{Results}: Found greatest potential for improvements is in shorter-term forecasts of operational trains. Initially scoped to do two-day ahead forecasts, but found that predictions beyond 24 hours were only marginally better than the schedule. Found an interesting edge case where trains with long delays did not report positions. 

% EXTREME LEARNING MACHINES
\subsection{Extreme learning machines}

ELMs are feedforward neural networks. They were introduced to overcome problems posed by backprop, namely "slow convergence rates, critical tuning of optimisation parameters, and presence of local minima necessitating multi-start and re-training strategies" \cite{oneto_et_al_2017a}.

%ONETO ET AL 2017
\subsubsection{Train Delay Prediction Systems: A Big Data Analytics Perspective \cite{oneto_et_al_2017a}}

\textit{Objectives}: to build a data-driven TDP system for large-scale railway networks that exploits the most recent big data technologies, learning algorithms, and statistical tools. 

\smallskip

\textit{Timescale}: online; real-time

\smallskip

\textit{Methodology}: Used Apache Spark in-memory technology. Explores the application of a both a shallow ELM (SELM) and a deep ELM (DELM). Uses 10-Fold Cross Validation to tune hyperparameters. For every train, DELM and SELM models were built, tuned. applied, and finally validated based on actual future data. 

\smallskip

\textit{Data}: 6 months, from January 2016 to June 2016, of train movements records from the entire Italian railway network.

\smallskip

\textit{Results}: DELM is up to 200\% more performant than the current system in use. SELM all shows improvements. but not to the same extent. For DELM, a deep architecture with a small number of neurons in each layer is preferred.

%ONETO ET AL 2017b (thresholdout)
\subsubsection{Dynamic Delay Predictions for Large-Scale Railway Networks: Deep and Shallow Extreme Learning Machines Tuned via Thresholdout \cite{oneto_et_al_2017b}}

\textit{Objectives}: To develop a dynamic data-driven TDP system that allows exploiting both historical data about train movements and exogenous data about the weather. 

\smallskip

\textit{Timescale}: Online; real-time

\smallskip

\textit{Methodology}: Used Apache Spark in-memory technology. Explores the application of a both a shallow ELM (SELM) and a deep ELM (DELM). For every train, DELM and SELM models were built, tuned. applied, and finally validated based on actual future data. Uses the thresholdout procedure to optimise the hyperparameters of SELM and DELM.

\smallskip

\textit{Data}: 6 months, from January 2016 to June 2016, of train movements records from the entire Italian railway network, and weather data covering the region. 

\smallskip

\textit{Results}: DELM tuned via thresholdout is the best performing model, with up to 2x better accuracy that then current RFI model, and superior performance to DELM tuned via the standard hold out method (cross validation). 

% SUPPORT VECTOR REGRESSION
\subsection{Support vector regression}

Support vector regression (SVR) is a popular ML model that uses support vector machines (SVMs) to predict continuous values. 

%MARKOVIC ET AL 2015
\subsubsection{Analyzing passenger train arrival delays with support vector regression \cite{markovic_et_al_2015}}

\textit{Objectives}: Develop a model to capture the relation between passenger train arrival delays and various characteristics of a railway system, specifically infrastructure.

\smallskip

\textit{Timescale}: offline; short-term; long-term

\smallskip

\textit{Methodology}: First application of an SVR to TDP.  Compared an ANN and SVR. Categorical variables were converted to binary variables, trained using Levenberg-Marquardt backprop. 100 independent ANNs were trained and the outputs averaged. Considers seven variables: passenger train category, scheduled time of arrival at station, infrastructure influence defined by expert opinions (discussed later), percent of journey completed distance-wise, distance travelled, time travelled, and headway.

\smallskip

\textit{Data}:  727 passenger trains (99 long-distance, 321 regional, 307 suburban, northbound towards Belgrade. Delays recorded on a minute scale.

\smallskip

\textit{Results}: Found that scheduled time of arrival and headway are not strongly correlated with any other co-variates. SVR performed better than the ANN.

%BARBOUR ET AL 2018
\subsubsection{Prediction of arrival times of freight traffic on US railroads using support vector regression \cite{barbour_et_al_2018}}

\textit{Objectives}: To develop a data-driven approach to predict estimated arrival times (ETAs) of individual freights trains. 

\smallskip

\textit{Timescale}: Online; real-time 

\smallskip

\textit{Methodology}: Construct distinct regression model for each origin-destination pair for which predictions are required. All of the same form; differ only in feature weights and hyper-parameters. Test four different SVR-based algorithms: three linear, with varying input features, and one RBF (radial basis function) kernel SVR. RBF kernel offers no improvement over fully-featured linear kernel. Only needed to train 140 models. Estimate 10,000 models for all ETA predictions.

\smallskip

\textit{Data}: Used freight train movement, train car operations, crew, and locomotive data. Network data is extracted from dispatching, operations, and signalling data. Final features: train length, train tonnage, train horsepower per ton, train priority, crew time remaining, on duty time to departure, full traffic count, directional traffic count, available sidings. 

\smallskip

\textit{Results}: Large gains from including track segment occupancy features. Results compare close to a deep NN trained on the same dataset (average improvement of 16\%, max of 25\%)
RBF kernel SVR offers a mean 14.3\% improvement, a max 21.8\%. Don't report on prediction error. Notes the difficulty of using features that change such the amount of traffic on the line of the road, the number of available sidings (as trains enter and leave).

% EXOGENOUS DATA
\clearpage
\section{Exogenous data}

It is widely accepted in ML that the greater the quantity of information available for the creation of a model, the greater the performance of that model will be. Features can either be \textit{engineered} from existing data or incorporated from \textit{exogenous} data. Data is exogenous if it is independent of other input data but the output data is dependent on it. The scope for inclusion is essentially limitless: any source of data which may affect railway operations is a viable candidate. This section explores the use of exogenous data in the selected studies according to the classification defined previously: weather, infrastructure, maintenance, and "other".

% WEATHER
\subsection{Weather}

Weather data is the most popular candidate for inclusion. It was first used in a TDP model, to the best of the authors' knowledge, in \cite{oneto_et_al_2016}. It is expected that weather-induced delays are seasonal, with heat causing delays in summer, rain and leaves causing delays in autumn, and snow and ice causing delays in winter: \cite{brazil_2017} found that most weather-caused delays occurred in the last third of the year, with a peak in November. There is also, naturally, a geographical element to the influence of weather on train delays: more temperate climes are likely to have less extreme weather, and so fewer delays due to that weather. \cite{wang_et_al_2019} observed that in locations less prepared for specific types of severe weather - such as snowy weather in southern cities - delays were greater. \cite{oneto_et_al_2016} note that weather conditions can additionally influence passenger flow and consequently dwell times, which have already been described as a key influence on delays. 

Because weather is seasonal, it is important that models be trained with at least a year's worth of data: \cite{wang_et_al_2019} partly attribute the poor performance of their model to the short duration (1 January 2019 - 31 March 2019) of data collection. Resolution is also important. Hourly data, as might be expected, also improves the performance of a model \cite{nabian_et_al_2019}\cite{wang_et_al_2019}.

The fields used are fairly heterogeneous: maximum, minimum, and average temperature; some weather type category (e.g. cloudy; overcast; thunderstorm); wind speed; wind direction; and precipitation. More unusual fields include pressure \cite{oneto_et_al_2019}\cite{oneto_et_al_2016}\cite{oneto_et_al_2017b}, air quality \cite{wang_et_al_2019}.

\cite{oneto_et_al_2016} found that the inclusion of weather data improved the accuracy of their RF model by approximately 10\%, with the caveat that the further ahead in the future the forecast is (and thus the less accurate), the smaller this increase was. However, \cite{nair_et_al_2019} found that weather has only a small impact on delays; an analysis of delay attribution data showed that less than 3\% of delays were directly attributed to weather. \cite{wang_et_al_2019} found that in severe weather train delays are determined mainly by the type of bad weather. 

%INFRASTRUCTURE

\subsection{Infrastructure}

Infrastructure is the second most popular candidate for inclusion.  It is a thoroughly modelled in the analytical models for TDP, but is less common in data-driven models. Of the four papers to include infrastructure data, two use expert opinions to assign a score to track sections \cite{markovic_et_al_2015}\cite{milinkovic_et_al_2013}  and two use the data directly \cite{barbour_et_al_2018}\cite{nair_et_al_2019}.

In the former two, opinions are collected from traffic dispatchers, operators, and subject matter experts. Each line or section considered is assigned a score based on characteristics such as the number of tracks, the percentage of rail on which trains must travel at reduced speeds, the number of stations, stops, loops, level crossings, junctions, length, block section, track clear section (station distance, braking distance, automatic block system, centralised traffic control, axle counters, and so on.  

The Delphi method is used to produce a single output score. The obvious limitation of this method is that each section must be independently human-assessed; in rail networks thousands of kilometres in length, this is clearly impractical.  In \cite{markovic_et_al_2015}, only 39 lines were evaluated. A low score denotes a route with the highest number of infrastructural factors that could cause unplanned delays. The study found a strong correlation between expert opinions and train delays. 

\cite{barbour_et_al_2018} takes into account individual tracks, switches, mileposts, and terminals, in order to build a network graph describing single-track edges, multi-track edges, and single-track edges with sidings. 

\cite{nair_et_al_2019} reconstructs the network and estimate capacity directly from passing messages. Furthermore, the method used generated train-class specific networks. Station attributes used included the designated platform, station attributes, historical mean delay at tracks, platforms, actual platform, track allocation, and track / platform change status.

% Maintenance

\subsection{Maintenance}

\cite{nair_et_al_2019} used work zone information, indicating location, duration, and the likely impact on different train categories.

% Other

\subsection{Other}

No papers were found to incorporate accidents, vandalism, trespassing, fatalities, or strikes. Holidays are, however, included in \cite{nair_et_al_2019}\cite{oneto_et_al_2017b}.

% EVALUATION
\section{Evaluation}

%WHAT ML MODELS ARE COMMONLY USED FOR TDP?
\subsection{RQ1: What ML models are commonly used for TDP?}

A wide variety of ML models have been applied to TDP. Interest in the area has only really developed in the past decade, and this is reflected in the bias towards recent studies in this review. 

Neural networks make only a brief appearance in \cite{yaghini_et_al_2013}, though they are often used as a benchmark to compare more sophisticated models against. More esoteric ML models, such as fuzzy Petri nets, are also used in \cite{milinkovic_et_al_2013}, although without further development. Some more simple papers \cite{wang_work_2015} use regression. Support vector regression is applied in \cite{barbour_et_al_2018}\cite{markovic_et_al_2015} . Markov chains are also used, but only in a limited context, in \cite{gaurav_et_al_2018}.

Currently at the forefront of research are three models: random forests \cite{nabian_et_al_2019}\cite{nair_et_al_2019}\cite{oneto_et_al_2016}, Bayesian networks \cite{corman_kecman_2018}\cite{lessan_fu_wen_2019} and extreme learning machines \cite{oneto_et_al_2017a}\cite{oneto_et_al_2017b}. 

Increasingly, these models are combined into an ensemble or hybrid model, as in \cite{nair_et_al_2019} (random forests, kernel regression, and mesoscopic simulation) and \cite{oneto_et_al_2019} (random forests, experienced-based model).

For the author's own work, the methodology and model structure described in \cite{nair_et_al_2019} is deemed most suitable for as a basis for exploration, with scope limited to the real-time: the approach is state-of-the-art, thoroughly described, and uses data very similar to that available to that of the author. Additionally, their models are entirely data-driven, and so do not require a close working relationship with a railway manager to define the rules of an experience-based model as used in \cite{oneto_et_al_2019}.

%WHAT EXOGENOUS DATA IS USED TO IMPROVE THE PERFOMANCE OF ML MODELS?
\subsection{RQ2: What exogenous data is used to improve the performance of ML models?}

A four-way classification was defined for exogenous data: weather, infrastructure, maintenance, and 'other'. 

Weather was first used in \cite{oneto_et_al_2016}, and has subsequently been investigated in \cite{brazil_2017} and applied in \cite{nabian_et_al_2019}\cite{nair_et_al_2019}\cite{wang_et_al_2019}. \cite{oneto_et_al_2016} found 10\% performance increase when incorporating weather data into their RF model. However, \cite{nair_et_al_2019} cast doubt on the effect of weather: only 3\% of delays in their dataset were directly attributable to weather. The authors plan to do their own statistical analysis of delay attribution records to verify this figure for UK weather, which is legendarily temperamental. Detailed weather data will be used by the author.

Infrastructure is the next most popular. \cite{markovic_et_al_2015} \cite{milinkovic_et_al_2013} use the expert opinions of dispatchers to derive an infrastructure score, and find a strong correlation between this score and severity of delays. \cite{nair_et_al_2019} takes a more programmatic approach and reverse engineer characteristics such as capacity and network structure directly from their dataset. \cite{barbour_et_al_2018} uses characteristics directly in their freight-based model. The author has detailed data on infrastructure available, so the reconstruction technique of \cite{nair_et_al_2019} is unnecessary, although it will also be explored. 

Maintenance is used only by \cite{nair_et_al_2019}, who quite rightfully claim to have constructed the most comprehensive dataset yet for TDP. The authors will also use historical data of maintenance work.

% WHAT ARE THE CURRENT RESEARCH AREAS OF TDP?
\subsection{RQ3: What are the current research areas of TDP?}

From the studies selected for this review, and additional reading, the authors identify the following avenues for potential research:

\begin {itemize}
	\item Combining the expertise of dispatchers with big data. This was first done in \cite{oneto_et_al_2019}. This approach is intended to overcome the limitations of both, but is restricted by the inclusion only of weather data. It is robust against rare and extreme events, which data-driven models often do not extrapolate well to \cite{barbour_et_al_2018}.
	\item Using different models for different categories of trains. Delay distributions vary considerably based on time horizon, train type, service class, and current delay \cite{nair_et_al_2019}. Trains would therefore ideally be clustered by similarity, with different models trained for each cluster. This is the approach taken in the hybrid model of \cite{oneto_et_al_2019}, which essentially comprises a decision tree in which each leaf is itself a random forest for such a cluster. 
	\item The unification of different timeframes. \cite{nair_et_al_2019} tackle both the short-term and medium-term by using separate ensembles for each, but a model that covers the real-time, short-term, and long-term  is yet to be developed.
	\item Incorporating additional sources of exogenous data. None of the studies selected used passenger volume as an input feature, despite the great impact it has on dwell time (which is itself recognised to be key contributor to delays). Incorporating railway asset conditions (as recommended in \cite{oneto_et_al_2017a} would also likely improve model performance. 
	\item Incorporating delay attribution as part of the delay prediction process. This is touched on by \cite{oneto_et_al_2019}, with their concept of \textit{penalty cost}. It is of great importance for both railway operators - who are typically penalised for delays they are responsible for - and passengers, for whom claiming compensation for delay is impossible without a clear attribution. Delay root cause identification has been studied in \cite{lee_et_al_2016}, with impressive accuracy.
\end {itemize}

The ideal TDP system would incorporate all of the above features, as well as those desirable for all ML models - efficient computation, robustness in the face of outliers, and easy interpretation. 

%CONCLUSION
\section{Conclusion}

We performed a systematic literature review for applications of machine learning in train delay prediction. A wide variety of studies and models have been discussed, and a suitable study \cite{nair_et_al_2019} has been selected as basis for the author's own. We have thoroughly investigated exogenous data used to improve the performance of these models, and potential future directions for research.

\printbibliography
 
\end{document}